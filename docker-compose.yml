# Docker Compose file version
version: '3.8'

# Define all the services (containers) we want to run
services:
  
  # Main chatbot application
  chatbot:
    # Build the image from our Dockerfile
    build: 
      context: .           # Use current directory
      dockerfile: Dockerfile
    
    # Give the container a friendly name
    container_name: voice_chatbot_app
    
    # Map ports: host_port:container_port
    # This makes the app accessible at localhost:5000
    ports:
      - "5000:5000"
    
    # Environment variables for the container
    environment:
      - FLASK_ENV=production
      - FLASK_DEBUG=false
    
    # Load environment variables from .env file
    # This includes your GEMINI_API_KEY
    env_file:
      - .env
    
    # Mount volumes to persist data outside the container
    # format: host_path:container_path
    volumes:
      - ./instance:/app/instance          # Database files
      - ./logs:/app/logs                  # Log files  
      - ./static/audio:/app/static/audio  # Generated audio files
    
    # Restart policy: restart if the container crashes
    restart: unless-stopped
    
    # Wait for database to be ready before starting
    # (uncomment if using database service below)
    # depends_on:
    #   - postgres
    
    # Connect to our custom network
    networks:
      - chatbot-network

  # Optional: PostgreSQL database
  # Uncomment this section if you want a separate database
  # postgres:
  #   image: postgres:15-alpine
  #   container_name: voice_chatbot_db
  #   environment:
  #     POSTGRES_DB: chatbot
  #     POSTGRES_USER: chatbot_user
  #     POSTGRES_PASSWORD: secure_password_change_this
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #   ports:
  #     - "5432:5432"
  #   restart: unless-stopped
  #   networks:
  #     - chatbot-network

  # Optional: Redis for session storage and caching
  # Uncomment if you want to add Redis
  # redis:
  #   image: redis:7-alpine
  #   container_name: voice_chatbot_redis
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redis_data:/data
  #   restart: unless-stopped
  #   networks:
  #     - chatbot-network
  #   command: redis-server --appendonly yes

  # Optional: Nginx reverse proxy for production
  # Uncomment for production deployment with SSL
  # nginx:
  #   image: nginx:alpine
  #   container_name: voice_chatbot_nginx
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx.conf:/etc/nginx/nginx.conf
  #     - ./ssl:/etc/nginx/ssl
  #   depends_on:
  #     - chatbot
  #   restart: unless-stopped
  #   networks:
  #     - chatbot-network

# Define named volumes for data that should persist
# These store data outside containers so it survives container restarts
volumes:
  # Uncomment if using PostgreSQL
  # postgres_data:
  #   driver: local
  
  # Uncomment if using Redis  
  # redis_data:
  #   driver: local

# Create a custom network for our services to communicate
# This allows containers to find each other by name
networks:
  chatbot-network:
    driver: bridge
